Cкрипт представляет собой автоматизированный сценарий Bash для развертывания и настройки кластера Apache Hadoop (версии 3.4.0) на rkfcntht.

1. Инициализация и переменные
Скрипт начинает с определения конфигурационных параметров:

Версия Hadoop: 3.4.0.
Пользователь: Создается специальный пользователь hadoop, от имени которого будет работать кластер.
Сетевая топология:
JN (JumpNode): Узел управления, с которого запускается скрипт.
NN (NameNode): Главный узел файловой системы HDFS.
DN00, DN01 (DataNodes): Рабочие узлы для хранения данных.
Определены IP-адреса и имена хостов для всех узлов.
2. Настройка SSH-доступа (для текущего пользователя)
Для беспарольного управления узлами скрипт настраивает SSH-ключи:

Генерируется SSH-ключ (ed25519) для текущего пользователя, если он еще не существует.
Публичный ключ добавляется в authorized_keys.
Файл authorized_keys копируется на все узлы кластера, чтобы скрипт мог подключаться к ним без пароля.
3. Подготовка системы (Hosts и Пользователи)
В цикле происходит настройка каждого узла (JN, NN, DN00, DN01):

Имена хостов: С помощью hostnamectl устанавливаются правильные имена (например, team-05-nn).
Файл /etc/hosts: Очищаются старые записи и добавляются новые, связывающие внутренние IP-адреса с именами хостов. Это необходимо, чтобы узлы могли "видеть" друг друга по имени.
Создание пользователя: Создается системный пользователь hadoop (без пароля), который будет владельцем файлов Hadoop.
4. Настройка SSH для пользователя Hadoop
Hadoop требует беспарольного SSH-доступа от самого себя к себе и между узлами для запуска демонов:

Скрипт генерирует SSH-ключи внутри профиля пользователя hadoop на JumpNode.
Публичный ключ пользователя hadoop распространяется на все узлы в их authorized_keys.
Выставляются правильные права доступа (.ssh — 700, authorized_keys — 600), что критично для безопасности SSH.
5. Установка Hadoop
Скачивание: Архив Hadoop загружается с официального зеркала Apache на JumpNode.
Распаковка: Архив распаковывается в домашнюю директорию пользователя hadoop.
Распространение: Распакованный архив копируется на остальные узлы через scp. Это гарантирует, что Hadoop установлен идентично на всех машинах.
6. Конфигурация Hadoop
Скрипт настраивает параметры окружения и XML-конфигурации:

Переменные окружения (.profile): Добавляются пути JAVA_HOME, HADOOP_HOME и обновляется PATH на всех узлах.
hadoop-env.sh: Указывается путь к Java.
core-site.xml: Определяет адрес NameNode (hdfs://team-05-nn:9000). Это "точка входа" в кластер.
hdfs-site.xml: Устанавливает коэффициент репликации (dfs.replication) равным 3.
workers: Определяет список рабочих узлов. В скрипте в этот список попадают NN, DN00, DN01 (NameNode также выступает в роли хранилища данных, что допустимо для малых кластеров).
Синхронизация: Конфигурационные файлы копируются на все узлы, заменяя стандартные.
7. Запуск кластера HDFS
Форматирование NameNode: Перед первым запуском файловая система форматируется командой hdfs namenode -format. Это происходит на узле NN.
Запуск: Выполняется скрипт start-dfs.sh на NameNode. Он по SSH подключается к узлам, перечисленным в workers, и запускает процессы DataNode, а также запускает NameNode.
8. Финальный этап (Верификация)
В самом конце скрипт создает SSH-туннель:
```sh
ssh -L 9870:$JN_IP:9870 $HADOOP_USER@$JN_EXT_IP
```
Это позволяет получить доступ к веб-интерфейсу Hadoop (NameNode UI), доступному обычно на порту 9870, через локальный компьютер пользователя, используя внешний IP JumpNode.
